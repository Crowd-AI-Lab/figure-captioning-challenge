{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "KpTSn3ufJGQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d444da3-689f-4b40-fbaa-adca94352fc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d30f10c37885dc6199e8e528da2a68f1cd2adf80929eddd0116fedf44c084cae\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpi21-3GjKf",
        "outputId": "a6c8a192-1532-4abd-9897-a68b3d50749e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import sys\n",
        "import os\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import json\n",
        "import codecs\n",
        "json_load = lambda x: json.load(codecs.open(x, 'r', encoding='utf-8'))\n",
        "json_dump = lambda d, p: json.dump(d, codecs.open(p, 'w', 'utf-8'), indent=2, ensure_ascii=False)\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge_score import rouge_scorer\n",
        "from scipy import interpolate\n",
        "from pathlib import Path\n",
        "from typing import List, Union, Iterable\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_map = {\n",
        "    \"rouge1\": [{\"length\": 3.984911270091982, \"score\": 0.06441979516467827},\n",
        "{\"length\": 5.958849763077208, \"score\": 0.09805036171757445},\n",
        "{\"length\": 7.908073957075165, \"score\": 0.1264078574240267},\n",
        "{\"length\": 9.815376753693208, \"score\": 0.14799855615831176},\n",
        "{\"length\": 11.669200037164362, \"score\": 0.16462272749307244},\n",
        "{\"length\": 13.424593514819287, \"score\": 0.1780456954008045},\n",
        "{\"length\": 15.064944718015425, \"score\": 0.18711340658961978},\n",
        "{\"length\": 16.568800520301032, \"score\": 0.19360401553241696},\n",
        "{\"length\": 17.935250394871318, \"score\": 0.1981390956396358},\n",
        "{\"length\": 19.17587103967295, \"score\": 0.2028477580052331},\n",
        "{\"length\": 20.205899842051473, \"score\": 0.20568411912661153},\n",
        "{\"length\": 21.183452568986343, \"score\": 0.20744671526261746},\n",
        "{\"length\": 21.977924370528665, \"score\": 0.20841666128479538},\n",
        "{\"length\": 26.75476168354548, \"score\": 0.21086241474611672},\n",
        "{\"length\": 52.85634116881911, \"score\": 0.2331159448484293},\n",
        "{\"length\": 77.34764470872433, \"score\": 0.22772254093882188},\n",
        "{\"length\": 99.4468085106383, \"score\": 0.21670611535128495},\n",
        "{\"length\": 118.99010498931523, \"score\": 0.20656306793005602},\n",
        "{\"length\": 135.94575861748584, \"score\": 0.1984243073734219},\n",
        "{\"length\": 150.71153953358728, \"score\": 0.19204958051321147},\n",
        "{\"length\": 163.3066710025086, \"score\": 0.1871192863560473},\n",
        "{\"length\": 174.03108798662086, \"score\": 0.1834498432953618},\n",
        "{\"length\": 183.1557837034284, \"score\": 0.1806604090047676}],\n",
        "    \"rouge2\":[{\"length\": 3.984911270091982, \"score\": 0.012204318074850343},\n",
        "{\"length\": 5.958849763077208, \"score\": 0.023002475506111737},\n",
        "{\"length\": 7.908073957075165, \"score\": 0.03455646883959736},\n",
        "{\"length\": 9.815376753693208, \"score\": 0.043565859835247536},\n",
        "{\"length\": 11.669200037164362, \"score\": 0.05076404631862093},\n",
        "{\"length\": 13.424593514819287, \"score\": 0.056914830457828657},\n",
        "{\"length\": 15.064944718015425, \"score\": 0.06113690491038822},\n",
        "{\"length\": 16.568800520301032, \"score\": 0.06379210133931756},\n",
        "{\"length\": 17.935250394871318, \"score\": 0.06558818891078552},\n",
        "{\"length\": 19.17587103967295, \"score\": 0.06856054937431301},\n",
        "{\"length\": 20.205899842051473, \"score\": 0.07002250650151698},\n",
        "{\"length\": 21.183452568986343, \"score\": 0.0707186916351147},\n",
        "{\"length\": 21.977924370528665, \"score\": 0.07123874205675668},\n",
        "{\"length\": 26.75476168354548, \"score\": 0.0737207868745392},\n",
        "{\"length\": 52.85634116881911, \"score\": 0.08887700947793167},\n",
        "{\"length\": 77.34764470872433, \"score\": 0.09367539519260709},\n",
        "{\"length\": 99.4468085106383, \"score\": 0.09468673311905121},\n",
        "{\"length\": 118.99010498931523, \"score\": 0.09422323872038459},\n",
        "{\"length\": 135.94575861748584, \"score\": 0.09365316220876337},\n",
        "{\"length\": 150.71153953358728, \"score\": 0.09293310736739671},\n",
        "{\"length\": 163.3066710025086, \"score\": 0.09214270076293635},\n",
        "{\"length\": 174.03108798662086, \"score\": 0.09153337352167813},\n",
        "{\"length\": 183.1557837034284, \"score\": 0.09106333800837592}],\n",
        "\"rougeL\":[{\"length\": 3.984911270091982, \"score\": 0.0603069994104717},\n",
        "{\"length\": 5.958849763077208, \"score\": 0.08865593606672337},\n",
        "{\"length\": 7.908073957075165, \"score\": 0.11183012948421223},\n",
        "{\"length\": 9.815376753693208, \"score\": 0.12830974766110848},\n",
        "{\"length\": 11.669200037164362, \"score\": 0.14071397628227003},\n",
        "{\"length\": 13.424593514819287, \"score\": 0.14983513211146812},\n",
        "{\"length\": 15.064944718015425, \"score\": 0.15586398800876933},\n",
        "{\"length\": 16.568800520301032, \"score\": 0.15967759189458222},\n",
        "{\"length\": 17.935250394871318, \"score\": 0.16221029161539405},\n",
        "{\"length\": 19.17587103967295, \"score\": 0.16514231726929202},\n",
        "{\"length\": 20.205899842051473, \"score\": 0.16692078881009273},\n",
        "{\"length\": 21.183452568986343, \"score\": 0.16762166739283607},\n",
        "{\"length\": 21.977924370528665, \"score\": 0.16775785324386341},\n",
        "{\"length\": 26.75476168354548, \"score\": 0.16851432006298805},\n",
        "{\"length\": 52.85634116881911, \"score\": 0.17676076320959805},\n",
        "{\"length\": 77.34764470872433, \"score\": 0.17027247886644845},\n",
        "{\"length\": 99.4468085106383, \"score\": 0.16223875947025201},\n",
        "{\"length\": 118.99010498931523, \"score\": 0.15543184730581103},\n",
        "{\"length\": 135.94575861748584, \"score\": 0.15041118174002338},\n",
        "{\"length\": 150.71153953358728, \"score\": 0.14662785591147373},\n",
        "{\"length\": 163.3066710025086, \"score\": 0.14359477578260552},\n",
        "{\"length\": 174.03108798662086, \"score\": 0.1415072129787698},\n",
        "{\"length\": 183.1557837034284, \"score\": 0.13990352023938848}]\n",
        "}"
      ],
      "metadata": {
        "id": "ySkkZZ4cJAHL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScicapSummarizationEval():\n",
        "    def __init__(self):\n",
        "        self.metric_list = [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "        self.rouge = rouge_scorer.RougeScorer(\n",
        "            self.metric_list,\n",
        "            use_stemmer=True,\n",
        "        )\n",
        "\n",
        "        # build score normalization\n",
        "        \n",
        "        self.normalization_funcs = {}\n",
        "        for metric in self.metric_list:\n",
        "            random_data = rouge_map[metric]\n",
        "            length_list = np.array([d[\"length\"] for d in random_data])\n",
        "            score_list = np.array([d[\"score\"] for d in random_data])\n",
        "            normalization_func = interpolate.interp1d(\n",
        "                length_list,\n",
        "                score_list,\n",
        "                bounds_error=False,\n",
        "                fill_value=\"extrapolate\",\n",
        "            )\n",
        "            self.normalization_funcs[metric] = normalization_func\n",
        "        \n",
        "    def clean_text(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def evaluate(\n",
        "        self, \n",
        "        hypothesis: List[str],\n",
        "        reference: List[str],\n",
        "    ):\n",
        "        assert len(hypothesis) == len(reference), \"The number of hypothesis and reference must be the same.\"\n",
        "\n",
        "        score_list = []\n",
        "        for hyp, ref in zip(hypothesis, reference):\n",
        "            hyp = self.clean_text(hyp)\n",
        "            ref = self.clean_text(ref)\n",
        "\n",
        "            # compute scores and match\n",
        "            scores = self.rouge.score(ref, hyp)\n",
        "            bleu = sentence_bleu([ref.split()], hyp.split())\n",
        "            score_dict = {\n",
        "                \"rouge1\": scores[\"rouge1\"].fmeasure,\n",
        "                \"rouge2\": scores[\"rouge2\"].fmeasure,\n",
        "                \"rougeL\": scores[\"rougeL\"].fmeasure,\n",
        "                \"length\": len(word_tokenize(hyp)),\n",
        "                \"bleu-4\": bleu\n",
        "            }\n",
        "            score_list.append(score_dict)\n",
        "        \n",
        "        # compute mean and normalize scores\n",
        "        score_dict = {\n",
        "            \"length\": np.mean([d[\"length\"] for d in score_list]),\n",
        "        }\n",
        "        for metric in self.metric_list:\n",
        "            score_dict[metric] = np.mean([d[metric] for d in score_list])\n",
        "            score_dict[f\"{metric}_normalized\"] = score_dict[metric] / self.normalization_funcs[metric](score_dict[\"length\"])\n",
        "        score_dict[\"bleu-4\"] = np.mean([d[\"bleu-4\"] for d in score_list])\n",
        "        return score_dict\n",
        "        \n",
        "def evaluate(test_annotation_file, user_submission_file, **kwargs):\n",
        "    print(\"Starting Evaluation.....\")\n",
        "    #for metric, score in cocoEval.eval.items():\n",
        "    #    print(metric, score)\n",
        "\n",
        "    # load data\n",
        "    ground_truth = json_load(test_annotation_file)\n",
        "    submission = json_load(user_submission_file)\n",
        "    \n",
        "    print(\"align annotations and submission file..\")\n",
        "    # align data\n",
        "    data = {sample[\"image_id\"]: sample for sample in ground_truth[\"annotations\"]}\n",
        "    for prediction in submission:\n",
        "        image_id = prediction[\"image_id\"]\n",
        "        data[image_id][\"prediction\"] = prediction[\"caption\"]\n",
        "\n",
        "    # convert to list\n",
        "    hypothesis = []\n",
        "    reference = []\n",
        "    print(data)\n",
        "    for image_id, sample in data.items():\n",
        "        try:\n",
        "            hypothesis.append(sample[\"prediction\"])\n",
        "            reference.append(sample[\"caption\"])\n",
        "        except:\n",
        "          print(\"Missing id: \", image_id)\n",
        "          return\n",
        "\n",
        "    # evaluate\n",
        "    evaluator = ScicapSummarizationEval()\n",
        "    score = evaluator.evaluate(\n",
        "        hypothesis=hypothesis,\n",
        "        reference=reference,\n",
        "    )\n",
        "\n",
        "    output = {}\n",
        "    output[\"result\"] = [\n",
        "        {\n",
        "            \"test_split\": {\n",
        "                \"BLEU-4\": score['bleu-4'],\n",
        "                \"Rouge-1\": score['rouge1'],\n",
        "                \"Rouge-1-normalized\": score['rouge1_normalized'],\n",
        "                \"Rouge-2\": score['rouge2'],\n",
        "                \"Rouge-2-normalized\": score['rouge2_normalized'],\n",
        "                \"Rouge-L\": score['rougeL'],\n",
        "                \"Rouge-L-normalized\": score['rougeL_normalized'],\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    # To display the results in the result file\n",
        "    output[\"submission_result\"] = output[\"result\"][0]\n",
        "    print(\"Completed evaluation!\")\n",
        "    return output"
      ],
      "metadata": {
        "id": "dOl_KlfOIdCe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"/content/test_annotations_devsplit.json\", \"/content/submission_dev.json\")"
      ],
      "metadata": {
        "id": "oz3jBiEBIfer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65957862-c357-434f-f890-5c171a1ebd4d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Evaluation.....\n",
            "align annotations and submission file..\n",
            "{7424363: {'image_id': 7424363, 'id': 8492163, 'caption': 'Fig. 1. The coefficient of Pe2 in the small-Pe optimal enhancement (32) with n = 1 (first zero). The optimal enhancement is achieved for m = 2, then drops off slowly.', 'caption_no_index': 'The coefficient of Pe2 in the small-Pe optimal enhancement (32) with n =  (first zero). The optimal enhancement is achieved for m = 2, then drops off slowly.', 'paragraph': ['Since j m,n increases monotonically with n, we must take n = 1 to minimize T . Thus the optimal streamlines pattern displays a single cell in the radial direction. It is then a simple matter of enumerating the zeros j m,1 to find that the integrated mean exit time is minimized for (m, n) = (2, 1), independent of the Péclet number (see Figure 1). The streamline and mean exit time patterns are illustrated in Figure 2.'], 'mention': [['It is then a simple matter of enumerating the zeros j m,1 to find that the integrated mean exit time is minimized for (m, n) = (2, 1), independent of the Péclet number (see Figure 1).']], 'prediction': 'The optimal enhancement is achieved for m = 2, then drops off slowly.'}}\n",
            "Completed evaluation!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result': [{'test_split': {'BLEU-4': 0.25042009669367926,\n",
              "    'Rouge-1': 0.5714285714285715,\n",
              "    'Rouge-1-normalized': 3.0597864207058603,\n",
              "    'Rouge-2': 0.5499999999999999,\n",
              "    'Rouge-2-normalized': 9.020867687902546,\n",
              "    'Rouge-L': 0.5714285714285715,\n",
              "    'Rouge-L-normalized': 3.6718232461202764}}],\n",
              " 'submission_result': {'test_split': {'BLEU-4': 0.25042009669367926,\n",
              "   'Rouge-1': 0.5714285714285715,\n",
              "   'Rouge-1-normalized': 3.0597864207058603,\n",
              "   'Rouge-2': 0.5499999999999999,\n",
              "   'Rouge-2-normalized': 9.020867687902546,\n",
              "   'Rouge-L': 0.5714285714285715,\n",
              "   'Rouge-L-normalized': 3.6718232461202764}}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}